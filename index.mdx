---
title: "Introduction"
description: "Observability and security for your text-based LLM applications"
---

# Asymetry SDK

> **Zero-code observability for OpenAI & Anthropic text workloads** â€“ built for modern LLM Ops.

Asymetry is a comprehensive observability platform for text-based LLM applications. Our Python SDK automatically instruments your OpenAI and Anthropic calls, captures detailed telemetry, and provides security analysis to help you build safer AI applications.

<Info>
Asymetry focuses exclusively on **text-based LLM tracing**. We capture prompts, completions, and all text interactions with full fidelity.
</Info>

<CardGroup cols={2}>
  <Card
    title="Quickstart"
    icon="rocket"
    href="/quickstart"
  >
    Get up and running in under 5 minutes
  </Card>
  <Card
    title="SDK Reference"
    icon="book"
    href="/sdk/overview"
  >
    Complete API reference for the Python SDK
  </Card>
  <Card
    title="Security Analysis"
    icon="shield-check"
    href="/api-reference/security-analysis"
  >
    Understand prompt risks and output safety
  </Card>
  <Card
    title="Examples"
    icon="code"
    href="/guides/basic-usage"
  >
    Real-world usage examples and patterns
  </Card>
</CardGroup>

---

## Why Asymetry?

<AccordionGroup>
  <Accordion icon="wand-magic-sparkles" title="Automatic Instrumentation">
    Just call `init_observability()` and we automatically capture all your OpenAI and Anthropic API calls. No code changes to your existing LLM logic required.
  </Accordion>
  <Accordion icon="chart-line" title="Rich Telemetry">
    Capture everything: latency, token usage, prompts, completions, errors, and trace correlations. Get complete visibility into your LLM operations.
  </Accordion>
  <Accordion icon="shield" title="Security Analysis">
    Automatically detect prompt injection attempts, jailbreaks, PII exposure, and toxic content. Get risk scores for every interaction.
  </Accordion>
  <Accordion icon="layer-group" title="OpenTelemetry Native">
    Built on OpenTelemetry for seamless integration with your existing observability stack. Custom tracing for your business logic with decorators and context managers.
  </Accordion>
</AccordionGroup>

---

## Capability Highlights

| Feature | Description |
| --- | --- |
| **Auto-instrumentation** | Monkey patches OpenAI and Anthropic SDKs with one call |
| **Rich Span Payloads** | Request/response, token usage, errors with stack traces |
| **Custom Tracing** | `@observe` decorator and `trace_context` for business logic |
| **Production Exporter** | Lock-free queue, batching, retry/backoff, graceful shutdown |
| **Security Scoring** | Prompt risk, output safety, and PII detection |

---

## Supported Providers

<CardGroup cols={2}>
  <Card title="OpenAI" icon="robot" href="/providers/openai">
    Full support for `chat.completions.create` with streaming support coming soon
  </Card>
  <Card title="Anthropic" icon="message" href="/providers/anthropic">
    Full support for `messages.create` including tool use and system prompts
  </Card>
</CardGroup>

---

## Get Started

```bash
pip install asymetry
```

```python
from asymetry import init_observability
import openai

init_observability()

client = openai.OpenAI()
response = client.chat.completions.create(
    model="gpt-4o-mini",
    messages=[{"role": "user", "content": "Hello!"}]
)
# Automatically tracked! ðŸŽ‰
```

<Card title="Continue to Quickstart" icon="arrow-right" href="/quickstart">
  Follow our step-by-step guide to set up Asymetry in your project
</Card>
