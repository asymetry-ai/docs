---
title: "Quickstart"
description: "Get started with Asymetry in under 5 minutes"
---

# Quickstart

Get your LLM application instrumented with full observability in just a few steps.

## Prerequisites

- Python 3.10 or higher
- An Asymetry account ([sign up here](https://asymetry.co))
- OpenAI or Anthropic API key

---

## Step 1: Install the SDK

<CodeGroup>
```bash pip
pip install asymetry
```

```bash poetry
poetry add asymetry
```
</CodeGroup>

<Tip>
For accurate token counting, also install `tiktoken`:
```bash
pip install tiktoken
```
</Tip>

---

## Step 2: Set Your API Key

Get your API key from the [Asymetry Dashboard](https://asymetry.co) and set it as an environment variable:

```bash
export ASYMETRY_API_KEY="sk_..."
```

Or create a `.env` file in your project root:

```bash .env
ASYMETRY_API_KEY=sk_...
ASYMETRY_ENABLED=true
```

---

## Step 3: Initialize Observability

Add a single line at the start of your application:

```python
from asymetry import init_observability

init_observability()
```

That's it! All your OpenAI and Anthropic calls are now automatically tracked.

---

## Step 4: Make LLM Calls

Use your LLM client normally – Asymetry captures everything automatically:

<CodeGroup>
```python OpenAI
from asymetry import init_observability
import openai

init_observability()

client = openai.OpenAI()

response = client.chat.completions.create(
    model="gpt-4o-mini",
    messages=[{"role": "user", "content": "What is the capital of France?"}],
    temperature=0.7,
)

print(response.choices[0].message.content)
# → "The capital of France is Paris."
# Automatically tracked: latency, tokens, prompt, response ✓
```

```python Anthropic
from asymetry import init_observability
import anthropic

init_observability()

client = anthropic.Anthropic()

response = client.messages.create(
    model="claude-3-5-haiku-latest",
    max_tokens=200,
    messages=[{"role": "user", "content": "What is the capital of France?"}],
)

print(response.content[0].text)
# Automatically tracked ✓
```
</CodeGroup>

---

## Step 5: View Your Traces

Head to the [Asymetry Dashboard](https://asymetry.co) to see your traces:

- **Request/Response**: Full prompts and completions
- **Token Usage**: Prompt, completion, and total tokens
- **Latency**: End-to-end timing for each call
- **Security Analysis**: Risk scores and security flags

---

## Optional: Graceful Shutdown

For short-lived scripts or tests, explicitly flush remaining spans before exiting:

```python
from asymetry import shutdown_observability

# At the end of your script
shutdown_observability(timeout=10)
```

<Info>
For long-running applications (web servers, etc.), spans are automatically flushed periodically and on process exit via `atexit`.
</Info>

---

## Next Steps

<CardGroup cols={2}>
  <Card title="Installation" icon="download" href="/installation">
    Detailed installation options and dependencies
  </Card>
  <Card title="Configuration" icon="gear" href="/sdk/configuration">
    All configuration options and environment variables
  </Card>
  <Card title="Custom Tracing" icon="code" href="/sdk/tracing">
    Add observability to your own functions
  </Card>
  <Card title="Security Analysis" icon="shield" href="/api-reference/security-analysis">
    Understand security scoring
  </Card>
</CardGroup>
